{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba107a6-3397-495a-87bb-2d28ca483aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                               text\n",
      "0           5                                            배공빠르고 굿\n",
      "1           2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
      "2           5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
      "3           2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
      "4           5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ\n",
      "...       ...                                                ...\n",
      "199995      2                                    장마라그런가!!! 달지않아요\n",
      "199996      5  다이슨 케이스 구매했어요 다이슨 슈퍼소닉 드라이기 케이스 구매했어요가격 괜찮고 배송...\n",
      "199997      5                    로드샾에서 사는것보다 세배 저렴하네요 ㅜㅜ 자주이용할께요\n",
      "199998      5                                      넘이쁘고 쎄련되보이네요~\n",
      "199999      5   아직 사용해보지도않았고 다른 제품을 써본적이없어서 잘 모르겠지만 ㅎㅎ 배송은 빨랐습니다\n",
      "\n",
      "[200000 rows x 2 columns]\n",
      "총 샘플의 수 :  200000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file = pd.read_table('./data/Data.txt') # DataFrame 으로 불러오기\n",
    "print(data_file)\n",
    "print('총 샘플의 수 : ', len(data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed472952-8a4d-44ee-a7ee-eee6c2b7c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label                                               text\n",
      "0           5                                            배공빠르고 굿\n",
      "1           2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
      "2           5  아주좋아요 바지 정말 좋아서개 더 구매했어요 이가격에 대박입니다 바느질이 조금 엉성...\n",
      "3           2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다 전화...\n",
      "4           5                   민트색상 예뻐요 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ\n",
      "...       ...                                                ...\n",
      "199995      2                                       장마라그런가 달지않아요\n",
      "199996      5  다이슨 케이스 구매했어요 다이슨 슈퍼소닉 드라이기 케이스 구매했어요가격 괜찮고 배송...\n",
      "199997      5                    로드샾에서 사는것보다 세배 저렴하네요 ㅜㅜ 자주이용할께요\n",
      "199998      5                                       넘이쁘고 쎄련되보이네요\n",
      "199999      5   아직 사용해보지도않았고 다른 제품을 써본적이없어서 잘 모르겠지만 ㅎㅎ 배송은 빨랐습니다\n",
      "\n",
      "[199908 rows x 2 columns]\n",
      "총 샘플의 수 :  199908\n"
     ]
    }
   ],
   "source": [
    "data_file.drop_duplicates(subset=['text'], inplace=True) # 중복제거\n",
    "data_file['text'] = data_file['text'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True) # 기타 문자 제거\n",
    "data_file = data_file.dropna(how = 'any') # null값 제거\n",
    "print(data_file)\n",
    "print('총 샘플의 수 : ', len(data_file))\n",
    "\n",
    "data_file.to_csv('./data/processed_data.txt', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "21738756-6669-4312-9d84-3687d6948774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader.py\n",
    "from torchtext.legacy import data\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(\n",
    "        self, train_fn,\n",
    "        batch_size = 64,\n",
    "        valid_ratio=.2,\n",
    "        device = -1,\n",
    "        max_vocab = 999999,\n",
    "        min_freq = 1,\n",
    "        use_eos = False,\n",
    "        shuffle = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label = data.Field(\n",
    "            sequential = False,\n",
    "            use_vocab = True,\n",
    "            unk_token = None\n",
    "        )\n",
    "        self.text = data.Field(\n",
    "            use_vocab = True,\n",
    "            batch_first = True,\n",
    "            include_lengths = False,\n",
    "            eos_token = '<EOS>' if use_eos else None\n",
    "        )\n",
    "\n",
    "        train, valid = data.TabularDataset(\n",
    "            path = train_fn,\n",
    "            format = 'tsv',\n",
    "            fields = [\n",
    "                ('label', self.label),\n",
    "                ('text', self.text)\n",
    "            ]\n",
    "        ).split(split_ratio = (1 - valid_ratio))\n",
    "        \n",
    "        self.train_loader, self.valid_loader = data.BucketIterator.splits(\n",
    "            (train, valid),\n",
    "            batch_size = batch_size,\n",
    "            device = 'cuda:%d' % device if device >= 0 else 'cpu',\n",
    "            shuffle = shuffle,\n",
    "            sort_key = lambda x: len(x.text),\n",
    "            sort_within_batch = True\n",
    "        )\n",
    "        \n",
    "        self.label.build_vocab(train)\n",
    "        self.text.build_vocab(train, max_size = max_vocab, min_freq = min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ad50b45-3135-44f3-8ec7-7b11b7afdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 word_vec_size,\n",
    "                 hidden_size,\n",
    "                 n_classes,\n",
    "                 n_layers = 4,\n",
    "                 dropout_p = .3\n",
    "                ):\n",
    "        self.vocab_size = input_size # vocabulary_size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(input_size, word_vec_size)\n",
    "        self.rnn = nn.LSTM(input_size = word_vec_size,\n",
    "                           hidden_size = hidden_size,\n",
    "                           num_layers = n_layers,\n",
    "                           dropout = dropout_p,\n",
    "                           batch_first = True,\n",
    "                           bidirectional = True\n",
    "                          )\n",
    "        self.generator = nn.Linear(hidden_size * 2, n_classes)\n",
    "        # We use LogSoftmax + NLLLoss instead of Softmax + CrossEntropy\n",
    "        self.activation = nn.LogSoftmax(dim = -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # /x/ = (batch_size, length)\n",
    "        x = self.emb(x)\n",
    "        # /x/ = (batch_size, length, word_vec_dim)\n",
    "        x, _ = self.rnn(x)\n",
    "        # /x/ = (batch_size, length, hidden_size * 2)\n",
    "        y = self.activation(self.generator(x[:, -1]))\n",
    "        # /y/ = (batch_size, n_classes)\n",
    "            \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fba5a31-e3be-4e38-8213-844d891770bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "923be011-d874-460a-becf-2c48832983ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        labels, texts = [], []\n",
    "        for line in lines:\n",
    "            if line.strip() != '':\n",
    "                # The file should have tab delimited two columns.\n",
    "                # First column indicates label field,\n",
    "                # and second column indicates text field.\n",
    "                label, text = line.strip().split('\\t')\n",
    "                labels += [label]\n",
    "                texts += [text]\n",
    "\n",
    "    return labels, texts\n",
    "\n",
    "\n",
    "def get_grad_norm(parameters, norm_type=2):\n",
    "    parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "\n",
    "    total_norm = 0\n",
    "\n",
    "    try:\n",
    "        for p in parameters:\n",
    "            total_norm += (p.grad.data**norm_type).sum()\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return total_norm\n",
    "\n",
    "\n",
    "def get_parameter_norm(parameters, norm_type=2):\n",
    "    total_norm = 0\n",
    "\n",
    "    try:\n",
    "        for p in parameters:\n",
    "            total_norm += (p.data**norm_type).sum()\n",
    "        total_norm = total_norm ** (1. / norm_type)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fafc20c-1b2a-438d-b6a7-caf215414c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from ignite.engine import Engine\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "\n",
    "VERBOSE_SILENT = 0\n",
    "VERBOSE_EPOCH_WISE = 1\n",
    "VERBOSE_BATCH_WISE = 2\n",
    "\n",
    "\n",
    "class MyEngine(Engine):\n",
    "\n",
    "    def __init__(self, func, model, crit, optimizer, config):\n",
    "        # Ignite Engine does not have objects in below lines.\n",
    "        # Thus, we assign class variables to access these object, during the procedure.\n",
    "        self.model = model\n",
    "        self.crit = crit\n",
    "        self.optimizer = optimizer\n",
    "        self.config = config\n",
    "\n",
    "        super().__init__(func) # Ignite Engine only needs function to run.\n",
    "\n",
    "        self.best_loss = np.inf\n",
    "        self.best_model = None\n",
    "\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    @staticmethod\n",
    "    def train(engine, mini_batch):\n",
    "        # You have to reset the gradients of all model parameters\n",
    "        # before to take another step in gradient descent.\n",
    "        engine.model.train() # Because we assign model as class variable, we can easily access to it.\n",
    "        engine.optimizer.zero_grad()\n",
    "\n",
    "        x, y = mini_batch.text, mini_batch.label\n",
    "        x, y = x.to(engine.device), y.to(engine.device)\n",
    "\n",
    "        x = x[:, :engine.config.max_length]\n",
    "\n",
    "        # Take feed-forward\n",
    "        y_hat = engine.model(x)\n",
    "\n",
    "        loss = engine.crit(y_hat, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Calculate accuracy only if 'y' is LongTensor,\n",
    "        # which means that 'y' is one-hot representation.\n",
    "        if isinstance(y, torch.LongTensor) or isinstance(y, torch.cuda.LongTensor):\n",
    "            accuracy = (torch.argmax(y_hat, dim=-1) == y).sum() / float(y.size(0))\n",
    "        else:\n",
    "            accuracy = 0\n",
    "\n",
    "        p_norm = float(get_parameter_norm(engine.model.parameters()))\n",
    "        g_norm = float(get_grad_norm(engine.model.parameters()))\n",
    "\n",
    "        # Take a step of gradient descent.\n",
    "        engine.optimizer.step()\n",
    "\n",
    "        return {\n",
    "            'loss': float(loss),\n",
    "            'accuracy': float(accuracy),\n",
    "            '|param|': p_norm,\n",
    "            '|g_param|': g_norm,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def validate(engine, mini_batch):\n",
    "        engine.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x, y = mini_batch.text, mini_batch.label\n",
    "            x, y = x.to(engine.device), y.to(engine.device)\n",
    "\n",
    "            x = x[:, :engine.config.max_length]\n",
    "\n",
    "            y_hat = engine.model(x)\n",
    "\n",
    "            loss = engine.crit(y_hat, y)\n",
    "\n",
    "            if isinstance(y, torch.LongTensor) or isinstance(y, torch.cuda.LongTensor):\n",
    "                accuracy = (torch.argmax(y_hat, dim=-1) == y).sum() / float(y.size(0))\n",
    "            else:\n",
    "                accuracy = 0\n",
    "\n",
    "        return {\n",
    "            'loss': float(loss),\n",
    "            'accuracy': float(accuracy),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def attach(train_engine, validation_engine, verbose=VERBOSE_BATCH_WISE):\n",
    "        # Attaching would be repaeted for serveral metrics.\n",
    "        # Thus, we can reduce the repeated codes by using this function.\n",
    "        def attach_running_average(engine, metric_name):\n",
    "            RunningAverage(output_transform=lambda x: x[metric_name]).attach(\n",
    "                engine,\n",
    "                metric_name,\n",
    "            )\n",
    "\n",
    "        training_metric_names = ['loss', 'accuracy', '|param|', '|g_param|']\n",
    "\n",
    "        for metric_name in training_metric_names:\n",
    "            attach_running_average(train_engine, metric_name)\n",
    "\n",
    "        # If the verbosity is set, progress bar would be shown for mini-batch iterations.\n",
    "        # Without ignite, you can use tqdm to implement progress bar.\n",
    "        if verbose >= VERBOSE_BATCH_WISE:\n",
    "            pbar = ProgressBar(bar_format=None, ncols=120)\n",
    "            pbar.attach(train_engine, training_metric_names)\n",
    "\n",
    "        # If the verbosity is set, statistics would be shown after each epoch.\n",
    "        if verbose >= VERBOSE_EPOCH_WISE:\n",
    "            @train_engine.on(Events.EPOCH_COMPLETED)\n",
    "            def print_train_logs(engine):\n",
    "                print('Epoch {} - |param|={:.2e} |g_param|={:.2e} loss={:.4e} accuracy={:.4f}'.format(\n",
    "                    engine.state.epoch,\n",
    "                    engine.state.metrics['|param|'],\n",
    "                    engine.state.metrics['|g_param|'],\n",
    "                    engine.state.metrics['loss'],\n",
    "                    engine.state.metrics['accuracy'],\n",
    "                ))\n",
    "\n",
    "        validation_metric_names = ['loss', 'accuracy']\n",
    "        \n",
    "        for metric_name in validation_metric_names:\n",
    "            attach_running_average(validation_engine, metric_name)\n",
    "\n",
    "        # Do same things for validation engine.\n",
    "        if verbose >= VERBOSE_BATCH_WISE:\n",
    "            pbar = ProgressBar(bar_format=None, ncols=120)\n",
    "            pbar.attach(validation_engine, validation_metric_names)\n",
    "\n",
    "        if verbose >= VERBOSE_EPOCH_WISE:\n",
    "            @validation_engine.on(Events.EPOCH_COMPLETED)\n",
    "            def print_valid_logs(engine):\n",
    "                print('Validation - loss={:.4e} accuracy={:.4f} best_loss={:.4e}'.format(\n",
    "                    engine.state.metrics['loss'],\n",
    "                    engine.state.metrics['accuracy'],\n",
    "                    engine.best_loss,\n",
    "                ))\n",
    "\n",
    "    @staticmethod\n",
    "    def check_best(engine):\n",
    "        loss = float(engine.state.metrics['loss'])\n",
    "        if loss <= engine.best_loss: # If current epoch returns lower validation loss,\n",
    "            engine.best_loss = loss  # Update lowest validation loss.\n",
    "            engine.best_model = deepcopy(engine.model.state_dict()) # Update best model weights.\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(engine, train_engine, config, **kwargs):\n",
    "        torch.save(\n",
    "            {\n",
    "                'model': engine.best_model,\n",
    "                'config': config,\n",
    "                **kwargs\n",
    "            }, config.model_fn\n",
    "        )\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        model, crit, optimizer,\n",
    "        train_loader, valid_loader,\n",
    "    ):\n",
    "        train_engine = MyEngine(\n",
    "            MyEngine.train,\n",
    "            model, crit, optimizer, self.config\n",
    "        )\n",
    "        validation_engine = MyEngine(\n",
    "            MyEngine.validate,\n",
    "            model, crit, optimizer, self.config\n",
    "        )\n",
    "\n",
    "        MyEngine.attach(\n",
    "            train_engine,\n",
    "            validation_engine,\n",
    "            verbose=self.config.verbose\n",
    "        )\n",
    "\n",
    "        def run_validation(engine, validation_engine, valid_loader):\n",
    "            validation_engine.run(valid_loader, max_epochs=1)\n",
    "\n",
    "        train_engine.add_event_handler(\n",
    "            Events.EPOCH_COMPLETED, # event\n",
    "            run_validation, # function\n",
    "            validation_engine, valid_loader, # arguments\n",
    "        )\n",
    "        validation_engine.add_event_handler(\n",
    "            Events.EPOCH_COMPLETED, # event\n",
    "            MyEngine.check_best, # function\n",
    "        )\n",
    "\n",
    "        train_engine.run(\n",
    "            train_loader,\n",
    "            max_epochs=self.config.n_epochs,\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(validation_engine.best_model)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1814d40c-b7c5-47fd-b869-a7467fbaba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        model, crit, optimizer,\n",
    "        train_loader, valid_loader,\n",
    "    ):\n",
    "        train_engine = MyEngine(\n",
    "            MyEngine.train,\n",
    "            model, crit, optimizer, self.config\n",
    "        )\n",
    "        validation_engine = MyEngine(\n",
    "            MyEngine.validate,\n",
    "            model, crit, optimizer, self.config\n",
    "        )\n",
    "\n",
    "        MyEngine.attach(\n",
    "            train_engine,\n",
    "            validation_engine,\n",
    "            verbose=self.config.verbose\n",
    "        )\n",
    "\n",
    "        def run_validation(engine, validation_engine, valid_loader):\n",
    "            validation_engine.run(valid_loader, max_epochs=1)\n",
    "\n",
    "        train_engine.add_event_handler(\n",
    "            Events.EPOCH_COMPLETED, # event\n",
    "            run_validation, # function\n",
    "            validation_engine, valid_loader, # arguments\n",
    "        )\n",
    "        validation_engine.add_event_handler(\n",
    "            Events.EPOCH_COMPLETED, # event\n",
    "            MyEngine.check_best, # function\n",
    "        )\n",
    "\n",
    "        train_engine.run(\n",
    "            train_loader,\n",
    "            max_epochs=self.config.n_epochs,\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(validation_engine.best_model)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3ce08272-115f-4720-92c2-34cb40cfd1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.model_fn = \"./models/model.pth\"\n",
    "        self.train_fn = \"./data/processed_data.txt\"\n",
    "        \n",
    "        self.gpu_id = \"mps\"\n",
    "        self.verbose = 2\n",
    "        \n",
    "        self.min_vocab_freq = 5\n",
    "        self.max_vocab_size = 999999\n",
    "        \n",
    "        self.batch_size = 256\n",
    "        self.n_epochs = 10\n",
    "        \n",
    "        self.word_vec_size = 256\n",
    "        self.dropout = .3\n",
    "        \n",
    "        self.max_length = 256\n",
    "        \n",
    "        self.rnn = True\n",
    "        self.hidden_size = 512\n",
    "        self.n_layers = 4\n",
    "        \n",
    "        self.cnn = False\n",
    "        self.use_batch_norm = True\n",
    "        self.window_sizes = [3, 4, 5]\n",
    "        self.n_filters = [100, 100, 100]\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6581e924-707b-4079-b6bc-9f4bfe5fcdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = DataLoader(\n",
    "    train_fn=config.train_fn,\n",
    "    batch_size=config.batch_size,\n",
    "    min_freq=config.min_vocab_freq,\n",
    "    max_vocab=config.max_vocab_size,\n",
    "    device=config.gpu_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2eb6f08-780c-410f-b736-4ac4404e97f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|train| = 159927 |valid| = 39982\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    '|train| =', len(loaders.train_loader.dataset),\n",
    "    '|valid| =', len(loaders.valid_loader.dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ccfb76b-55b9-4d66-a420-43c0f9134ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|vocab| = 26113 |classes| = 5\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(loaders.text.vocab)\n",
    "n_classes = len(loaders.label.vocab)\n",
    "print('|vocab| =', vocab_size, '|classes| =', n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ebedc709-8f56-4caa-a83d-a6554382d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.rnn is False and config.cnn is False:\n",
    "    raise Exception('You need to specify an architecture to train. (--rnn or --cnn)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77f46c0e-df16-4ac7-b9b1-c65ce13eed57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNClassifier(\n",
      "  (emb): Embedding(26113, 256)\n",
      "  (rnn): LSTM(256, 512, num_layers=4, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (generator): Linear(in_features=1024, out_features=5, bias=True)\n",
      "  (activation): LogSoftmax(dim=-1)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - |param|=2.59e+03 |g_param|=4.72e-01 loss=8.8598e-01 accuracy=0.6215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=8.6510e-01 accuracy=0.6107 best_loss=inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - |param|=2.59e+03 |g_param|=4.26e-01 loss=8.2865e-01 accuracy=0.6377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=8.3318e-01 accuracy=0.6296 best_loss=8.6510e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - |param|=2.60e+03 |g_param|=4.22e-01 loss=7.7081e-01 accuracy=0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=8.2444e-01 accuracy=0.6343 best_loss=8.3318e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - |param|=2.60e+03 |g_param|=4.24e-01 loss=7.1206e-01 accuracy=0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=8.5704e-01 accuracy=0.6315 best_loss=8.2444e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - |param|=2.61e+03 |g_param|=4.52e-01 loss=6.3293e-01 accuracy=0.7306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=9.1699e-01 accuracy=0.6227 best_loss=8.2444e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - |param|=2.61e+03 |g_param|=5.33e-01 loss=5.4878e-01 accuracy=0.7747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.0345e+00 accuracy=0.6064 best_loss=8.2444e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - |param|=2.62e+03 |g_param|=5.67e-01 loss=4.7101e-01 accuracy=0.8085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.1805e+00 accuracy=0.6112 best_loss=8.2444e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - |param|=2.62e+03 |g_param|=6.21e-01 loss=3.9345e-01 accuracy=0.8425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.4098e+00 accuracy=0.5948 best_loss=8.2444e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - |param|=2.62e+03 |g_param|=6.43e-01 loss=3.3403e-01 accuracy=0.8633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.5375e+00 accuracy=0.5996 best_loss=8.2444e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - |param|=2.63e+03 |g_param|=6.42e-01 loss=3.0087e-01 accuracy=0.8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - loss=1.7107e+00 accuracy=0.5950 best_loss=8.2444e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if config.rnn:\n",
    "    # Declare model and loss.\n",
    "    model = RNNClassifier(\n",
    "        input_size=vocab_size,\n",
    "        word_vec_size=config.word_vec_size,\n",
    "        hidden_size=config.hidden_size,\n",
    "        n_classes=n_classes,\n",
    "        n_layers=config.n_layers,\n",
    "        dropout_p=config.dropout,\n",
    "    )\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    crit = nn.NLLLoss()\n",
    "    print(model)\n",
    "\n",
    "    if config.gpu_id >= 0:\n",
    "        model.cuda(config.gpu_id)\n",
    "        crit.cuda(config.gpu_id)\n",
    "\n",
    "    rnn_trainer = Trainer(config)\n",
    "    rnn_model = rnn_trainer.train(\n",
    "        model,\n",
    "        crit,\n",
    "        optimizer,\n",
    "        loaders.train_loader,\n",
    "        loaders.valid_loader\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7d44a71-4e9a-44cb-8d9c-19f8bb7a70a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(__name__ == '__main__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3011e9b9-d91a-437d-95a8-a83c9195bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'rnn': rnn_model.state_dict() if config.rnn else None,\n",
    "    'cnn': cnn_model.state_dict() if config.cnn else None,\n",
    "    'config': config,\n",
    "    'vocab': loaders.text.vocab,\n",
    "    'classes': loaders.label.vocab,\n",
    "}, config.model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cc08b8d4-db46-460e-9fb0-1b9080c31902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6def2f5a-bf09-43b8-99b0-c77b70c38173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(input_string, max_length=256):\n",
    "    '''\n",
    "    Read text from standard input for inference.\n",
    "    '''\n",
    "    lines = []\n",
    "\n",
    "    for line in input_string: # sys.stdin:\n",
    "        if line.strip() != '':\n",
    "            lines += [line.strip().split(' ')[:max_length]]\n",
    "\n",
    "    return lines\n",
    "\n",
    "def define_field():\n",
    "    '''\n",
    "    To avoid use DataLoader class, just declare dummy fields. \n",
    "    With those fields, we can retore mapping table between words and indice.\n",
    "    '''\n",
    "    return (\n",
    "        data.Field(\n",
    "            use_vocab=True,\n",
    "            batch_first=True,\n",
    "            include_lengths=False,\n",
    "        ),\n",
    "        data.Field(\n",
    "            sequential=False,\n",
    "            use_vocab=True,\n",
    "            unk_token=None,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "eec82aa7-8770-4420-b633-b5c3dbc8c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_Config():\n",
    "    def __init__(self):\n",
    "        self.model_fn = \"./models/model.pth\"\n",
    "        self.gpu_id = -1\n",
    "        self.batch_size = 256\n",
    "        self.top_k = 1\n",
    "        self.max_length = 256\n",
    "        \n",
    "        self.drop_rnn = False\n",
    "        self.drop_cnn = True\n",
    "\n",
    "test_config = test_Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "65f1eac2-1c1e-405c-998a-ad9383caf642",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = [\n",
    "    \"이건 쓰레기야\",\n",
    "    \"최고에요! ㅎㅎ\",\n",
    "    \"구매하길 잘 했네요\",\n",
    "    \"실망이에요.. 금방 망가지네요\",\n",
    "    \"다시는 구매 안합니다.\",\n",
    "    \"또 주문할게요.\",\n",
    "    \"포장도 제대로 안되어있고 정말 엉망이네요\",\n",
    "    \"내돈 돌려줘\",\n",
    "    \"사이즈가 안맞아요\",\n",
    "    \"따듯하고 좋아요 세탁하면 어떨지 아직은 모르겠네요 세탁후 줄어듬만 없으면 100점이에요\",\n",
    "    \"이정도면 무난히 만족합니다. 다른분들은 모르겠지만 딱 제가 찾던 폴라티네요.\",\n",
    "    \"남들이 욕하길래 정말 궁금해서 사봤어요 우와 세상에ㅎㅎ 잠옷이 생겼네요 요즘 좀 우울했는에 웃음이 나오네요ㅋㅋ 옷감은 무지 얇고 목은 왜이리 긴지 난 목이기니까 하면서 샀는데 어느나라에 목이 긴 부족에게 추천하고 싶네요 돈많고 좀 우울한 분에게 기분전환용으로 추천합니다 덕분에 웃었어요\",\n",
    "    \"다신 안삼\",\n",
    "    \"인연끊고 싶은 사람에게 추천해라\",\n",
    "    \"이런 입지도 못하는 옷을 팔다니 싸더라도 입을 수 있게는 만들어야지 기장이 짧아서 배꼽이 보일지경ㅜㅜ\",\n",
    "    \"한마디로 잘라 말하면 사지 마세요.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fe2a436a-f2e5-43ac-b055-40fed0e4dd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['이건', '쓰레기야'], ['최고에요!', 'ㅎㅎ'], ['구매하길', '잘', '했네요'], ['실망이에요..', '금방', '망가지네요'], ['다시는', '구매', '안합니다.'], ['또', '주문할게요.'], ['포장도', '제대로', '안되어있고', '정말', '엉망이네요'], ['내돈', '돌려줘'], ['사이즈가', '안맞아요'], ['따듯하고', '좋아요', '세탁하면', '어떨지', '아직은', '모르겠네요', '세탁후', '줄어듬만', '없으면', '100점이에요'], ['이정도면', '무난히', '만족합니다.', '다른분들은', '모르겠지만', '딱', '제가', '찾던', '폴라티네요.'], ['남들이', '욕하길래', '정말', '궁금해서', '사봤어요', '우와', '세상에ㅎㅎ', '잠옷이', '생겼네요', '요즘', '좀', '우울했는에', '웃음이', '나오네요ㅋㅋ', '옷감은', '무지', '얇고', '목은', '왜이리', '긴지', '난', '목이기니까', '하면서', '샀는데', '어느나라에', '목이', '긴', '부족에게', '추천하고', '싶네요', '돈많고', '좀', '우울한', '분에게', '기분전환용으로', '추천합니다', '덕분에', '웃었어요'], ['다신', '안삼'], ['인연끊고', '싶은', '사람에게', '추천해라'], ['이런', '입지도', '못하는', '옷을', '팔다니', '싸더라도', '입을', '수', '있게는', '만들어야지', '기장이', '짧아서', '배꼽이', '보일지경ㅜㅜ'], ['한마디로', '잘라', '말하면', '사지', '마세요.']]\n",
      "2\t이건 쓰레기야\n",
      "5\t최고에요! ㅎㅎ\n",
      "5\t구매하길 잘 했네요\n",
      "2\t실망이에요.. 금방 망가지네요\n",
      "1\t다시는 구매 안합니다.\n",
      "5\t또 주문할게요.\n",
      "1\t포장도 제대로 안되어있고 정말 엉망이네요\n",
      "1\t내돈 돌려줘\n",
      "2\t사이즈가 안맞아요\n",
      "5\t따듯하고 좋아요 세탁하면 어떨지 아직은 모르겠네요 세탁후 줄어듬만 없으면 100점이에요\n",
      "2\t이정도면 무난히 만족합니다. 다른분들은 모르겠지만 딱 제가 찾던 폴라티네요.\n",
      "5\t남들이 욕하길래 정말 궁금해서 사봤어요 우와 세상에ㅎㅎ 잠옷이 생겼네요 요즘 좀 우울했는에 웃음이 나오네요ㅋㅋ 옷감은 무지 얇고 목은 왜이리 긴지 난 목이기니까 하면서 샀는데 어느나라에 목이 긴 부족에게 추천하고 싶네요 돈많고 좀 우울한 분에게 기분전환용으로 추천합니다 덕분에 웃었어요\n",
      "1\t다신 안삼\n",
      "2\t인연끊고 싶은 사람에게 추천해라\n",
      "1\t이런 입지도 못하는 옷을 팔다니 싸더라도 입을 수 있게는 만들어야지 기장이 짧아서 배꼽이 보일지경ㅜㅜ\n",
      "1\t한마디로 잘라 말하면 사지 마세요.\n"
     ]
    }
   ],
   "source": [
    "# saved_data = torch.load(\n",
    "#     config.model_fn,\n",
    "#     map_location='cpu' if config.gpu_id < 0 else 'cuda:%d' % config.gpu_id\n",
    "# )\n",
    "\n",
    "# train_config = saved_data['config']\n",
    "# rnn_best = saved_data['rnn']\n",
    "# cnn_best = saved_data['cnn']\n",
    "# vocab = saved_data['vocab']\n",
    "# classes = saved_data['classes']\n",
    "\n",
    "\n",
    "train_config = config\n",
    "rnn_best = rnn_model.state_dict() if config.rnn else None\n",
    "cnn_best = cnn_model.state_dict() if config.cnn else None\n",
    "vocab = loaders.text.vocab\n",
    "classes = loaders.label.vocab\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "n_classes = len(classes)\n",
    "\n",
    "text_field, label_field = define_field()\n",
    "text_field.vocab = vocab\n",
    "label_field.vocab = classes\n",
    "\n",
    "lines = read_text(input_string, max_length=test_config.max_length)\n",
    "print(lines)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ensemble = []\n",
    "    if rnn_best is not None and not test_config.drop_rnn:\n",
    "        # Declare model and load pre-trained weights.\n",
    "        model = RNNClassifier(\n",
    "            input_size=vocab_size,\n",
    "            word_vec_size=train_config.word_vec_size,\n",
    "            hidden_size=train_config.hidden_size,\n",
    "            n_classes=n_classes,\n",
    "            n_layers=train_config.n_layers,\n",
    "            dropout_p=train_config.dropout,\n",
    "        )\n",
    "        model.load_state_dict(rnn_best)\n",
    "        ensemble += [model]\n",
    "    if cnn_best is not None and not test_config.drop_cnn:\n",
    "        # Declare model and load pre-trained weights.\n",
    "        model = CNNClassifier(\n",
    "            input_size=vocab_size,\n",
    "            word_vec_size=train_config.word_vec_size,\n",
    "            n_classes=n_classes,\n",
    "            use_batch_norm=train_config.use_batch_norm,\n",
    "            dropout_p=train_config.dropout,\n",
    "            window_sizes=train_config.window_sizes,\n",
    "            n_filters=train_config.n_filters,\n",
    "        )\n",
    "        model.load_state_dict(cnn_best)\n",
    "        ensemble += [model]\n",
    "\n",
    "    y_hats = []\n",
    "    # Get prediction with iteration on ensemble.\n",
    "    for model in ensemble:\n",
    "        if test_config.gpu_id >= 0:\n",
    "            model.cuda(test_config.gpu_id)\n",
    "        # Don't forget turn-on evaluation mode.\n",
    "        model.eval()\n",
    "\n",
    "        y_hat = []\n",
    "        for idx in range(0, len(lines), test_config.batch_size):                \n",
    "            # Converts string to list of index.\n",
    "            x = text_field.numericalize(\n",
    "                text_field.pad(lines[idx:idx + test_config.batch_size]),\n",
    "                device='cuda:%d' % test_config.gpu_id if test_config.gpu_id >= 0 else 'cpu',\n",
    "            )\n",
    "\n",
    "            y_hat += [model(x).cpu()]\n",
    "        # Concatenate the mini-batch wise result\n",
    "        y_hat = torch.cat(y_hat, dim=0)\n",
    "        # |y_hat| = (len(lines), n_classes)\n",
    "\n",
    "        y_hats += [y_hat]\n",
    "\n",
    "        model.cpu()\n",
    "    # Merge to one tensor for ensemble result and make probability from log-prob.\n",
    "    y_hats = torch.stack(y_hats).exp()\n",
    "    # |y_hats| = (len(ensemble), len(lines), n_classes)\n",
    "    y_hats = y_hats.sum(dim=0) / len(ensemble) # Get average\n",
    "    # |y_hats| = (len(lines), n_classes)\n",
    "\n",
    "    probs, indice = y_hats.topk(test_config.top_k)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        sys.stdout.write('%s\\t%s\\n' % (\n",
    "            ' '.join([classes.itos[indice[i][j]] for j in range(test_config.top_k)]), \n",
    "            ' '.join(lines[i])\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0785fd61-fb03-4a71-9903-301be9fe9cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
