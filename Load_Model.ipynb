{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2308d4-ef42-424a-abab-77ca89fc0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c28d9b0-7890-464b-85fd-0075ee890b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 word_vec_size,\n",
    "                 hidden_size,\n",
    "                 n_classes,\n",
    "                 n_layers = 4,\n",
    "                 dropout_p = .3\n",
    "                ):\n",
    "        self.vocab_size = input_size # vocabulary_size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(input_size, word_vec_size)\n",
    "        self.rnn = nn.LSTM(input_size = word_vec_size,\n",
    "                           hidden_size = hidden_size,\n",
    "                           num_layers = n_layers,\n",
    "                           dropout = dropout_p,\n",
    "                           batch_first = True,\n",
    "                           bidirectional = True\n",
    "                          )\n",
    "        self.generator = nn.Linear(hidden_size * 2, n_classes)\n",
    "        # We use LogSoftmax + NLLLoss instead of Softmax + CrossEntropy\n",
    "        self.activation = nn.LogSoftmax(dim = -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # /x/ = (batch_size, length)\n",
    "        x = self.emb(x)\n",
    "        # /x/ = (batch_size, length, word_vec_dim)\n",
    "        x, _ = self.rnn(x)\n",
    "        # /x/ = (batch_size, length, hidden_size * 2)\n",
    "        y = self.activation(self.generator(x[:, -1]))\n",
    "        # /y/ = (batch_size, n_classes)\n",
    "            \n",
    "        return y\n",
    "    \n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.model_fn = \"./models/model.pth\"\n",
    "        self.train_fn = \"./data/processed_data.txt\"\n",
    "        \n",
    "        self.gpu_id = -1\n",
    "        self.verbose = 2\n",
    "        \n",
    "        self.min_vocab_freq = 5\n",
    "        self.max_vocab_size = 999999\n",
    "        \n",
    "        self.batch_size = 256\n",
    "        self.n_epochs = 10\n",
    "        \n",
    "        self.word_vec_size = 256\n",
    "        self.dropout = .3\n",
    "        \n",
    "        self.max_length = 256\n",
    "        \n",
    "        self.rnn = True\n",
    "        self.hidden_size = 512\n",
    "        self.n_layers = 4\n",
    "        \n",
    "        self.cnn = False\n",
    "        self.use_batch_norm = True\n",
    "        self.window_sizes = [3, 4, 5]\n",
    "        self.n_filters = [100, 100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219f8f71-aa03-4b73-a4b0-2618181075f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(input_string, max_length=256):\n",
    "    '''\n",
    "    Read text from standard input for inference.\n",
    "    '''\n",
    "    lines = []\n",
    "\n",
    "    for line in input_string: # sys.stdin:\n",
    "        if line.strip() != '':\n",
    "            lines += [line.strip().split(' ')[:max_length]]\n",
    "\n",
    "    return lines\n",
    "\n",
    "def define_field():\n",
    "    '''\n",
    "    To avoid use DataLoader class, just declare dummy fields. \n",
    "    With those fields, we can retore mapping table between words and indice.\n",
    "    '''\n",
    "    return (\n",
    "        data.Field(\n",
    "            use_vocab=True,\n",
    "            batch_first=True,\n",
    "            include_lengths=False,\n",
    "        ),\n",
    "        data.Field(\n",
    "            sequential=False,\n",
    "            use_vocab=True,\n",
    "            unk_token=None,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725ce36a-7124-478d-b3dc-37b755264fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_Config():\n",
    "    def __init__(self):\n",
    "        self.model_fn = \"./models/model.pth\"\n",
    "        self.gpu_id = -1\n",
    "        self.batch_size = 256\n",
    "        self.top_k = 1\n",
    "        self.max_length = 256\n",
    "        \n",
    "        self.drop_rnn = False\n",
    "        self.drop_cnn = True\n",
    "\n",
    "test_config = test_Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9efc6c37-6639-4221-8867-32373edb6f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Model(input_string):\n",
    "    saved_data = torch.load(\n",
    "        test_config.model_fn,\n",
    "        map_location='cpu' if test_config.gpu_id < 0 else 'cuda:%d' % test_config.gpu_id\n",
    "    )\n",
    "    \n",
    "    train_config = saved_data['config']\n",
    "    rnn_best = saved_data['rnn']\n",
    "    cnn_best = saved_data['cnn']\n",
    "    vocab = saved_data['vocab']\n",
    "    classes = saved_data['classes']\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    text_field, label_field = define_field()\n",
    "    text_field.vocab = vocab\n",
    "    label_field.vocab = classes\n",
    "\n",
    "    lines = read_text(input_string, max_length=test_config.max_length)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ensemble = []\n",
    "        if rnn_best is not None and not test_config.drop_rnn:\n",
    "            # Declare model and load pre-trained weights.\n",
    "            model = RNNClassifier(\n",
    "                input_size=vocab_size,\n",
    "                word_vec_size=train_config.word_vec_size,\n",
    "                hidden_size=train_config.hidden_size,\n",
    "                n_classes=n_classes,\n",
    "                n_layers=train_config.n_layers,\n",
    "                dropout_p=train_config.dropout,\n",
    "            )\n",
    "            model.load_state_dict(rnn_best)\n",
    "            ensemble += [model]\n",
    "        if cnn_best is not None and not test_config.drop_cnn:\n",
    "            # Declare model and load pre-trained weights.\n",
    "            model = CNNClassifier(\n",
    "                input_size=vocab_size,\n",
    "                word_vec_size=train_config.word_vec_size,\n",
    "                n_classes=n_classes,\n",
    "                use_batch_norm=train_config.use_batch_norm,\n",
    "                dropout_p=train_config.dropout,\n",
    "                window_sizes=train_config.window_sizes,\n",
    "                n_filters=train_config.n_filters,\n",
    "            )\n",
    "            model.load_state_dict(cnn_best)\n",
    "            ensemble += [model]\n",
    "\n",
    "        y_hats = []\n",
    "        # Get prediction with iteration on ensemble.\n",
    "        for model in ensemble:\n",
    "            if test_config.gpu_id >= 0:\n",
    "                model.cuda(test_config.gpu_id)\n",
    "            # Don't forget turn-on evaluation mode.\n",
    "            model.eval()\n",
    "\n",
    "            y_hat = []\n",
    "            for idx in range(0, len(lines), test_config.batch_size):                \n",
    "                # Converts string to list of index.\n",
    "                x = text_field.numericalize(\n",
    "                    text_field.pad(lines[idx:idx + test_config.batch_size]),\n",
    "                    device='cuda:%d' % test_config.gpu_id if test_config.gpu_id >= 0 else 'cpu',\n",
    "                )\n",
    "\n",
    "                y_hat += [model(x).cpu()]\n",
    "            # Concatenate the mini-batch wise result\n",
    "            y_hat = torch.cat(y_hat, dim=0)\n",
    "            # |y_hat| = (len(lines), n_classes)\n",
    "\n",
    "            y_hats += [y_hat]\n",
    "\n",
    "            model.cpu()\n",
    "        # Merge to one tensor for ensemble result and make probability from log-prob.\n",
    "        y_hats = torch.stack(y_hats).exp()\n",
    "        # |y_hats| = (len(ensemble), len(lines), n_classes)\n",
    "        y_hats = y_hats.sum(dim=0) / len(ensemble) # Get average\n",
    "        # |y_hats| = (len(lines), n_classes)\n",
    "\n",
    "        probs, indice = y_hats.topk(test_config.top_k)\n",
    "\n",
    "        for i in range(len(lines)):\n",
    "            sys.stdout.write('[%s, 점수:%s] %s\\n' % (\n",
    "                ' '.join(['긍정' if int(classes.itos[indice[i][j]]) > 3 else '부정' for j in range(test_config.top_k)]), \n",
    "                ' '.join([classes.itos[indice[i][j]] for j in range(test_config.top_k)]), \n",
    "                ' '.join(lines[i])\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d7b4c28-972b-45d2-a672-ebc17c5a4f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[긍정, 점수:5] 민경환 바보\n"
     ]
    }
   ],
   "source": [
    "# input_string = [\n",
    "#     \"이건 쓰레기야\",\n",
    "#     \"최고에요! ㅎㅎ\",\n",
    "#     \"구매하길 잘 했네요\",\n",
    "#     \"실망이에요.. 금방 망가지네요\",\n",
    "#     \"다시는 구매 안합니다.\",\n",
    "#     \"또 주문할게요.\",\n",
    "#     \"포장도 제대로 안되어있고 정말 엉망이네요\",\n",
    "#     \"내돈 돌려줘\",\n",
    "#     \"사이즈가 안맞아요\",\n",
    "#     \"따듯하고 좋아요 세탁하면 어떨지 아직은 모르겠네요 세탁후 줄어듬만 없으면 100점이에요\",\n",
    "#     \"이정도면 무난히 만족합니다. 다른분들은 모르겠지만 딱 제가 찾던 폴라티네요.\",\n",
    "#     \"남들이 욕하길래 정말 궁금해서 사봤어요 우와 세상에ㅎㅎ 잠옷이 생겼네요 요즘 좀 우울했는에 웃음이 나오네요ㅋㅋ 옷감은 무지 얇고 목은 왜이리 긴지 난 목이기니까 하면서 샀는데 어느나라에 목이 긴 부족에게 추천하고 싶네요 돈많고 좀 우울한 분에게 기분전환용으로 추천합니다 덕분에 웃었어요\",\n",
    "#     \"다신 안삼\",\n",
    "#     \"인연끊고 싶은 사람에게 추천해라\",\n",
    "#     \"이런 입지도 못하는 옷을 팔다니 싸더라도 입을 수 있게는 만들어야지 기장이 짧아서 배꼽이 보일지경ㅜㅜ\",\n",
    "#     \"한마디로 잘라 말하면 사지 마세요.\"\n",
    "# ]\n",
    "\n",
    "# input_string = [\n",
    "#     \"너무셔요 너무셔서애기가안먹네요 다른제품은잘먹었는데.. 제구매는없을듯요\",\n",
    "#     \"오배송 5단계주문했는데 4단계왔습니다 안보고 모르고 한팩 뜯어썻네요 그거 제외하고 다시 교환해주세요\",\n",
    "#     \"너무느려요 배송너무느려서 주문못하겠네요\",\n",
    "#     \"정말 박스 너덜너덜하고 기저귀 터져서왔네요 제가 어지간해선 리뷰 귀찮아서 안남기는데 제개 보낸 기저귀는 박스도 재포장해서 너덜너덜해져서 거의 분리된상태로 온데다가 안에 뜯어보니 박스가 그상태로 굴러와서인지 원래 뜯어진건지, 시킨것중 기저귀한팩 바닥이 반쯤 뜯어져서 왔네요. 박스도 첨부터 너덜너덜해서 급히 그부분 보수해서 테이핑해서 온데다가, 안에 내용물까지 저모냥인데 그것도 다른게아니라 아기 소중한데 닿을 기저귀인데 정말 해도해도 너무하시네요. 동영상 가지고있구요, 저도 놀고먹는사람아니라서 바빠 반품하기도 싫습니다. 다음부터는 다른건 몰라도 아기용품은 양심껏 파세요 ㅡㅡ\",\n",
    "#     \"배송진짜느림 배송진짜느려요 급한분들은 주문하시면 안될거같아요 피드백도 느려서 재고도없이 판매하면 어쩌라는건지;;\",\n",
    "#     \"최악 포장도 엉망 cs도엉망 배송최악\"\n",
    "# ]\n",
    "\n",
    "# input_string = [\n",
    "#     \"이거 정말 좋네요\",\n",
    "#     \"배송도 빠르고 제품상태가 좋아요\"\n",
    "# ]\n",
    "\n",
    "input_string = [\n",
    "    \"민경환 바보\"\n",
    "]\n",
    "\n",
    "Load_Model(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d583396-a603-4858-9145-d19ac01748f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
